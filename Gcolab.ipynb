{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version_info #Print python version info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea899b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to google gemini llm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyC59cfe2TxI5fs5Ijfyi6mBEpOpl2SP6RA\")\n",
    "MODEL_ID = \"gemini-2.5-flash-lite\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC59cfe2TxI5fs5Ijfyi6mBEpOpl2SP6RA\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the largest planet in our solar system?\"\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b033bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393da843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ef6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-adk==1.18.0\n",
    "##pip install -U -q 'pyngrok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb742f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fa788",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "    ),\n",
    "    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by using google search tool.\"\"\",\n",
    "    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "print(\"✅ root_agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06652a5e",
   "metadata": {},
   "source": [
    "### Write an MCP Tool based Agent   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f37468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Required for path operations\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\n",
    "from mcp import StdioServerParameters\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "\n",
    "mcp_image_server = McpToolset(\n",
    "    connection_params=StdioConnectionParams(\n",
    "        server_params=StdioServerParameters(\n",
    "            command=\"npx\",  # Run MCP server via npx\n",
    "            args=[\n",
    "                \"-y\",  # Argument for npx to auto-confirm install\n",
    "                \"@modelcontextprotocol/server-everything\",\n",
    "            ],\n",
    "            tool_filter=[\"getTinyImage\"],\n",
    "        ),\n",
    "        timeout=30,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ MCP Tool created\")\n",
    "\n",
    "image_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"image_agent\",\n",
    "    instruction=\"Use the MCP Tool to generate images for user queries\",\n",
    "    tools=[mcp_image_server],\n",
    ")\n",
    "\n",
    "# envlist_tool =  McpToolset(\n",
    "#             connection_params=StdioConnectionParams(\n",
    "#                 server_params = StdioServerParameters(\n",
    "#                     command='npx',\n",
    "#                     args=[\n",
    "#                         \"-y\",  # Argument for npx to auto-confirm install\n",
    "#                         \"@modelcontextprotocol/server-everything\"\n",
    "#                     ],\n",
    "#                     # Optional: Filter which tools from the MCP server are exposed\n",
    "#                 tool_filter=['printEnv', ]\n",
    "#                 ),\n",
    "#                 timeout=30\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "# root_agent_mcp = LlmAgent(\n",
    "#     model='gemini-2.0-flash',\n",
    "#     name='print_env_agent',\n",
    "#     instruction='Help the user print environment variables.',\n",
    "#     tools=[envlist_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = InMemoryRunner(agent=image_agent)\n",
    "response = await runner.run_debug(\"Provide a sample tiny image\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from http.server import HTTPServer, SimpleHTTPRequestHandler\n",
    "httpd = HTTPServer(('localhost', 8000), SimpleHTTPRequestHandler)\n",
    "httpd.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ee19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import getpass\n",
    "import os\n",
    "from http.server import HTTPServer, BaseHTTPRequestHandler\n",
    "\n",
    "port = 8888\n",
    "\n",
    "server_address = (\"\", port)\n",
    "httpd = HTTPServer(server_address, BaseHTTPRequestHandler)\n",
    "\n",
    "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "auth_token = getpass.getpass(\"ngrok authtoken: \")\n",
    "conf.get_default().auth_token = auth_token\n",
    "\n",
    "os.environ[\"NGROK_AUTHTOKEN\"] = auth_token\n",
    "\n",
    "# from pyngrok import ngrok\n",
    "public_url = ngrok.connect(port).public_url\n",
    "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
    "\n",
    "try:\n",
    "    # Block until CTRL-C or some other terminating event\n",
    "    httpd.serve_forever()\n",
    "except KeyboardInterrupt:\n",
    "   print(\" Shutting down server.\")\n",
    "\n",
    "   httpd.socket.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
